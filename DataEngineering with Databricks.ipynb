{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f49c85e-0907-45c9-ac21-356e75b3705f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SQL Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280411d7-0551-4f2c-8fca-86adc3ec078a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_catalog()</th><th>current_schema()</th></tr></thead><tbody><tr><td>workspace</td><td>default</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "workspace",
         "default"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "current_catalog()",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "current_schema()",
            "nullable": false,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 27
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "current_catalog()",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "current_schema()",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- saving catalog and schema \n",
    "use catalog workspace;\n",
    "use schema identifier('default');\n",
    "-- viewing schema and catalog\n",
    "select \n",
    "  current_catalog(),\n",
    "  current_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "716ad7f8-378d-4d3a-8162-2cb9af1e0a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>databaseName</th></tr></thead><tbody><tr><td>default</td></tr><tr><td>information_schema</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "default"
        ],
        [
         "information_schema"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "databaseName",
            "nullable": false,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 32
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "databaseName",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- command to view available schemas in the catalog\n",
    "show schemas in workspace;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ddc6526-50a4-48be-b93f-e4d74d98933d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database_description_item</th><th>database_description_value</th></tr></thead><tbody><tr><td>Catalog Name</td><td>workspace</td></tr><tr><td>Namespace Name</td><td>default</td></tr><tr><td>Comment</td><td>Default schema (auto-created)</td></tr><tr><td>Location</td><td></td></tr><tr><td>Owner</td><td>_workspace_admins_workspace_3815380049663645</td></tr><tr><td>Properties</td><td></td></tr><tr><td>Predictive Optimization</td><td>ENABLE (inherited from METASTORE metastore_aws_us_east_2)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Catalog Name",
         "workspace"
        ],
        [
         "Namespace Name",
         "default"
        ],
        [
         "Comment",
         "Default schema (auto-created)"
        ],
        [
         "Location",
         ""
        ],
        [
         "Owner",
         "_workspace_admins_workspace_3815380049663645"
        ],
        [
         "Properties",
         ""
        ],
        [
         "Predictive Optimization",
         "ENABLE (inherited from METASTORE metastore_aws_us_east_2)"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "database_description_item",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "database_description_value",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 38
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database_description_item",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "database_description_value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- To get the information about the schema (describe schema extended identifier('schema_name')- this is incase you've stored schema name in a var)\n",
    "describe schema extended default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d79576-e075-48c4-aea7-857736c4c436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>Id</td><td>bigint</td><td>null</td></tr><tr><td>Name</td><td>varchar(10)</td><td>null</td></tr><tr><td>Age</td><td>bigint</td><td>null</td></tr><tr><td>City</td><td>char(50)</td><td>null</td></tr><tr><td>Salary</td><td>decimal(7,2)</td><td>null</td></tr><tr><td>Gender</td><td>char(10)</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Delta Statistics Columns</td><td></td><td></td></tr><tr><td>Column Names</td><td>Id, Name, Age, City, Salary</td><td></td></tr><tr><td>Column Selection Method</td><td>first-32</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>workspace</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>sample_table</td><td></td></tr><tr><td>Created Time</td><td>Sat Jul 05 14:13:36 UTC 2025</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark </td><td></td></tr><tr><td>Statistics</td><td>3019 bytes, 3 rows</td><td></td></tr><tr><td>Type</td><td>MANAGED</td><td></td></tr><tr><td>Location</td><td></td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Owner</td><td>pamujulasainadh2001@gmail.com</td><td></td></tr><tr><td>Is_managed_location</td><td>true</td><td></td></tr><tr><td>Predictive Optimization</td><td>ENABLE (inherited from METASTORE metastore_aws_us_east_2)</td><td></td></tr><tr><td>Table Properties</td><td>[delta.columnMapping.maxColumnId=8,delta.columnMapping.mode=name,delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.columnMapping=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Constraints</td><td></td><td></td></tr><tr><td>sample_table_pk</td><td>PRIMARY KEY (`Id`)</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Id",
         "bigint",
         null
        ],
        [
         "Name",
         "varchar(10)",
         null
        ],
        [
         "Age",
         "bigint",
         null
        ],
        [
         "City",
         "char(50)",
         null
        ],
        [
         "Salary",
         "decimal(7,2)",
         null
        ],
        [
         "Gender",
         "char(10)",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Delta Statistics Columns",
         "",
         ""
        ],
        [
         "Column Names",
         "Id, Name, Age, City, Salary",
         ""
        ],
        [
         "Column Selection Method",
         "first-32",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "workspace",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "sample_table",
         ""
        ],
        [
         "Created Time",
         "Sat Jul 05 14:13:36 UTC 2025",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark ",
         ""
        ],
        [
         "Statistics",
         "3019 bytes, 3 rows",
         ""
        ],
        [
         "Type",
         "MANAGED",
         ""
        ],
        [
         "Location",
         "",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Owner",
         "pamujulasainadh2001@gmail.com",
         ""
        ],
        [
         "Is_managed_location",
         "true",
         ""
        ],
        [
         "Predictive Optimization",
         "ENABLE (inherited from METASTORE metastore_aws_us_east_2)",
         ""
        ],
        [
         "Table Properties",
         "[delta.columnMapping.maxColumnId=8,delta.columnMapping.mode=name,delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.columnMapping=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Constraints",
         "",
         ""
        ],
        [
         "sample_table_pk",
         "PRIMARY KEY (`Id`)",
         ""
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 45
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- to get the information about the tables\n",
    "describe table extended sample_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c8f2a8a-da14-4e17-ac7d-c41564eef16e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>catalog</th><th>database</th><th>owner</th><th>storage_location</th><th>volume_type</th><th>comment</th><th>securable_type</th><th>securable_kind</th></tr></thead><tbody><tr><td>volume_intro</td><td>workspace</td><td>default</td><td>pamujulasainadh2001@gmail.com</td><td></td><td>MANAGED</td><td>null</td><td>VOLUME</td><td>VOLUME_DB_STORAGE</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "volume_intro",
         "workspace",
         "default",
         "pamujulasainadh2001@gmail.com",
         "",
         "MANAGED",
         null,
         "VOLUME",
         "VOLUME_DB_STORAGE"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "catalog",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "database",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "owner",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "storage_location",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "volume_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "securable_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "securable_kind",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 57
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "catalog",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "owner",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "storage_location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "volume_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "securable_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "securable_kind",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- describa a volume\n",
    "describe volume volume_intro;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cc63ea7-3a78-4784-a402-74d2db7b8f5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modification_time</th></tr></thead><tbody><tr><td>/Volumes/workspace/default/volume_intro/Data.csv</td><td>Data.csv</td><td>228</td><td>1751712799000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/Volumes/workspace/default/volume_intro/Data.csv",
         "Data.csv",
         228,
         1751712799000
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "size",
            "nullable": false,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "modification_time",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 63
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modification_time",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- list files in a volume\n",
    "list '/Volumes/workspace/default/volume_intro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c946135c-af5d-4121-b61b-0ce01e65e52c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th></tr></thead><tbody><tr><td>1</td><td>Kelly</td><td>Ortiz</td><td>kortiz0@omniture.com</td><td>Female</td><td>252.115.158.159</td><td>3537905681760845</td><td>Russia</td><td>4/23/1980</td><td>277302.99</td><td>Nurse</td><td></td></tr><tr><td>2</td><td>Sharon</td><td>Carroll</td><td>scarroll1@disqus.com</td><td>Female</td><td>29.217.252.62</td><td>56022458507191696</td><td>Indonesia</td><td>8/28/1992</td><td>209258.05</td><td>Recruiter</td><td>åß∂ƒ©˙∆˚¬…æ</td></tr><tr><td>3</td><td>Ruth</td><td>Ross</td><td>rross2@cbc.ca</td><td>Female</td><td>220.224.80.32</td><td>3589642396435648</td><td>Benin</td><td>6/13/1994</td><td>18270.7</td><td>Design Engineer</td><td></td></tr><tr><td>4</td><td>Kelly</td><td>Meyer</td><td>kmeyer3@cornell.edu</td><td>Female</td><td>255.65.123.124</td><td></td><td>Philippines</td><td>1/6/1967</td><td>17485.27</td><td>Cost Accountant</td><td></td></tr><tr><td>5</td><td>Irene</td><td>Jordan</td><td>ijordan4@pagesperso-orange.fr</td><td>Female</td><td>162.57.23.136</td><td>3576848317807089</td><td>United States</td><td>1/4/1997</td><td>163979.38</td><td>Programmer Analyst III</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Kelly",
         "Ortiz",
         "kortiz0@omniture.com",
         "Female",
         "252.115.158.159",
         "3537905681760845",
         "Russia",
         "4/23/1980",
         277302.99,
         "Nurse",
         ""
        ],
        [
         2,
         "Sharon",
         "Carroll",
         "scarroll1@disqus.com",
         "Female",
         "29.217.252.62",
         "56022458507191696",
         "Indonesia",
         "8/28/1992",
         209258.05,
         "Recruiter",
         "åß∂ƒ©˙∆˚¬…æ"
        ],
        [
         3,
         "Ruth",
         "Ross",
         "rross2@cbc.ca",
         "Female",
         "220.224.80.32",
         "3589642396435648",
         "Benin",
         "6/13/1994",
         18270.7,
         "Design Engineer",
         ""
        ],
        [
         4,
         "Kelly",
         "Meyer",
         "kmeyer3@cornell.edu",
         "Female",
         "255.65.123.124",
         "",
         "Philippines",
         "1/6/1967",
         17485.27,
         "Cost Accountant",
         ""
        ],
        [
         5,
         "Irene",
         "Jordan",
         "ijordan4@pagesperso-orange.fr",
         "Female",
         "162.57.23.136",
         "3576848317807089",
         "United States",
         "1/4/1997",
         163979.38,
         "Programmer Analyst III",
         ""
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 26
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- query the parquet files by path in the directory to view raw data as a quick preview in table format\n",
    "select * \n",
    "from parquet.`/Volumes/workspace/v01/parquet`\n",
    "limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70b27059-e69e-475d-b0f0-dedf3e9d8e08",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752064385708}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th><th>_rescued_data</th></tr></thead><tbody><tr><td>1</td><td>Kelly</td><td>Ortiz</td><td>kortiz0@omniture.com</td><td>Female</td><td>252.115.158.159</td><td>3537905681760845</td><td>Russia</td><td>4/23/1980</td><td>277302.99</td><td>Nurse</td><td></td><td>null</td></tr><tr><td>2</td><td>Sharon</td><td>Carroll</td><td>scarroll1@disqus.com</td><td>Female</td><td>29.217.252.62</td><td>56022458507191696</td><td>Indonesia</td><td>8/28/1992</td><td>209258.05</td><td>Recruiter</td><td>åß∂ƒ©˙∆˚¬…æ</td><td>null</td></tr><tr><td>3</td><td>Ruth</td><td>Ross</td><td>rross2@cbc.ca</td><td>Female</td><td>220.224.80.32</td><td>3589642396435648</td><td>Benin</td><td>6/13/1994</td><td>18270.7</td><td>Design Engineer</td><td></td><td>null</td></tr><tr><td>4</td><td>Kelly</td><td>Meyer</td><td>kmeyer3@cornell.edu</td><td>Female</td><td>255.65.123.124</td><td></td><td>Philippines</td><td>1/6/1967</td><td>17485.27</td><td>Cost Accountant</td><td></td><td>null</td></tr><tr><td>5</td><td>Irene</td><td>Jordan</td><td>ijordan4@pagesperso-orange.fr</td><td>Female</td><td>162.57.23.136</td><td>3576848317807089</td><td>United States</td><td>1/4/1997</td><td>163979.38</td><td>Programmer Analyst III</td><td></td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Kelly",
         "Ortiz",
         "kortiz0@omniture.com",
         "Female",
         "252.115.158.159",
         "3537905681760845",
         "Russia",
         "4/23/1980",
         277302.99,
         "Nurse",
         "",
         null
        ],
        [
         2,
         "Sharon",
         "Carroll",
         "scarroll1@disqus.com",
         "Female",
         "29.217.252.62",
         "56022458507191696",
         "Indonesia",
         "8/28/1992",
         209258.05,
         "Recruiter",
         "åß∂ƒ©˙∆˚¬…æ",
         null
        ],
        [
         3,
         "Ruth",
         "Ross",
         "rross2@cbc.ca",
         "Female",
         "220.224.80.32",
         "3589642396435648",
         "Benin",
         "6/13/1994",
         18270.7,
         "Design Engineer",
         "",
         null
        ],
        [
         4,
         "Kelly",
         "Meyer",
         "kmeyer3@cornell.edu",
         "Female",
         "255.65.123.124",
         "",
         "Philippines",
         "1/6/1967",
         17485.27,
         "Cost Accountant",
         "",
         null
        ],
        [
         5,
         "Irene",
         "Jordan",
         "ijordan4@pagesperso-orange.fr",
         "Female",
         "162.57.23.136",
         "3576848317807089",
         "United States",
         "1/4/1997",
         163979.38,
         "Programmer Analyst III",
         "",
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 58
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Read parquet data with read_files\n",
    "select *\n",
    "from read_files('/Volumes/workspace/v01/parquet',format=> 'parquet')\n",
    "limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f662a5dc-fd07-490a-8f1e-a3ef540a6003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Batch Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7144294d-9dcf-4d24-a1c0-dea1005cac2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th><th>_rescued_data</th></tr></thead><tbody><tr><td>1</td><td>Amanda</td><td>Jordan</td><td>ajordan0@com.com</td><td>Female</td><td>null</td><td>6759521864920116</td><td>Indonesia</td><td>3/8/1971</td><td>49756.53</td><td>Internal Auditor</td><td>1E+02</td><td>null</td></tr><tr><td>2</td><td>Albert</td><td>Freeman</td><td>afreeman1@is.gd</td><td>Male</td><td>218.111.175.34</td><td></td><td>Canada</td><td>1/16/1968</td><td>150280.17</td><td>Accountant IV</td><td></td><td>null</td></tr><tr><td>3</td><td>Evelyn</td><td>Morgan</td><td>emorgan2@altervista.org</td><td>Female</td><td>7.161.136.94</td><td>6767119071901597</td><td>Russia</td><td>2/1/1960</td><td>144972.51</td><td>Structural Engineer</td><td></td><td>null</td></tr><tr><td>4</td><td>Denise</td><td>Riley</td><td>driley3@gmpg.org</td><td>Female</td><td>140.35.109.83</td><td>3576031598965625</td><td>China</td><td>4/8/1997</td><td>90263.05</td><td>Senior Cost Accountant</td><td></td><td>null</td></tr><tr><td>5</td><td>Carlos</td><td>Burns</td><td>cburns4@miitbeian.gov.cn</td><td></td><td>169.113.235.40</td><td>5602256255204850</td><td>South Africa</td><td></td><td>null</td><td></td><td></td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Amanda",
         "Jordan",
         "ajordan0@com.com",
         "Female",
         null,
         "6759521864920116",
         "Indonesia",
         "3/8/1971",
         49756.53,
         "Internal Auditor",
         "1E+02",
         null
        ],
        [
         2,
         "Albert",
         "Freeman",
         "afreeman1@is.gd",
         "Male",
         "218.111.175.34",
         "",
         "Canada",
         "1/16/1968",
         150280.17,
         "Accountant IV",
         "",
         null
        ],
        [
         3,
         "Evelyn",
         "Morgan",
         "emorgan2@altervista.org",
         "Female",
         "7.161.136.94",
         "6767119071901597",
         "Russia",
         "2/1/1960",
         144972.51,
         "Structural Engineer",
         "",
         null
        ],
        [
         4,
         "Denise",
         "Riley",
         "driley3@gmpg.org",
         "Female",
         "140.35.109.83",
         "3576031598965625",
         "China",
         "4/8/1997",
         90263.05,
         "Senior Cost Accountant",
         "",
         null
        ],
        [
         5,
         "Carlos",
         "Burns",
         "cburns4@miitbeian.gov.cn",
         "",
         "169.113.235.40",
         "5602256255204850",
         "South Africa",
         "",
         null,
         "",
         "",
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 12
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "--Drop the table if already exists\n",
    "drop table if exists parquet_bronze_ctas;\n",
    "\n",
    "-- create the table\n",
    "create table parquet_bronze_ctas\n",
    "select *\n",
    "from read_files('/Volumes/workspace/v01/parquet',format=> 'parquet');\n",
    "\n",
    "--preview the delta table\n",
    "select * from parquet_bronze_ctas\n",
    "limit 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e06e5e08-1d5e-425a-81fb-c3c8cb39af25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>id</td><td>int</td><td>null</td></tr><tr><td>first_name</td><td>string</td><td>null</td></tr><tr><td>last_name</td><td>string</td><td>null</td></tr><tr><td>email</td><td>string</td><td>null</td></tr><tr><td>gender</td><td>string</td><td>null</td></tr><tr><td>ip_address</td><td>string</td><td>null</td></tr><tr><td>cc</td><td>string</td><td>null</td></tr><tr><td>country</td><td>string</td><td>null</td></tr><tr><td>birthdate</td><td>string</td><td>null</td></tr><tr><td>salary</td><td>double</td><td>null</td></tr><tr><td>title</td><td>string</td><td>null</td></tr><tr><td>comments</td><td>string</td><td>null</td></tr><tr><td>_rescued_data</td><td>string</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Delta Statistics Columns</td><td></td><td></td></tr><tr><td>Column Names</td><td>first_name, email, country, salary, birthdate, id, last_name, ip_address, _rescued_data, cc, title, comments, gender</td><td></td></tr><tr><td>Column Selection Method</td><td>first-32</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>workspace</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>parquet_bronze_ctas</td><td></td></tr><tr><td>Created Time</td><td>Wed Jul 09 12:36:34 UTC 2025</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark </td><td></td></tr><tr><td>Statistics</td><td>171368 bytes, 3000 rows</td><td></td></tr><tr><td>Type</td><td>MANAGED</td><td></td></tr><tr><td>Location</td><td></td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Owner</td><td>pamujulasainadh2001@gmail.com</td><td></td></tr><tr><td>Is_managed_location</td><td>true</td><td></td></tr><tr><td>Predictive Optimization</td><td>ENABLE (inherited from METASTORE metastore_aws_us_east_2)</td><td></td></tr><tr><td>Table Properties</td><td>[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "id",
         "int",
         null
        ],
        [
         "first_name",
         "string",
         null
        ],
        [
         "last_name",
         "string",
         null
        ],
        [
         "email",
         "string",
         null
        ],
        [
         "gender",
         "string",
         null
        ],
        [
         "ip_address",
         "string",
         null
        ],
        [
         "cc",
         "string",
         null
        ],
        [
         "country",
         "string",
         null
        ],
        [
         "birthdate",
         "string",
         null
        ],
        [
         "salary",
         "double",
         null
        ],
        [
         "title",
         "string",
         null
        ],
        [
         "comments",
         "string",
         null
        ],
        [
         "_rescued_data",
         "string",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Delta Statistics Columns",
         "",
         ""
        ],
        [
         "Column Names",
         "first_name, email, country, salary, birthdate, id, last_name, ip_address, _rescued_data, cc, title, comments, gender",
         ""
        ],
        [
         "Column Selection Method",
         "first-32",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "workspace",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "parquet_bronze_ctas",
         ""
        ],
        [
         "Created Time",
         "Wed Jul 09 12:36:34 UTC 2025",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark ",
         ""
        ],
        [
         "Statistics",
         "171368 bytes, 3000 rows",
         ""
        ],
        [
         "Type",
         "MANAGED",
         ""
        ],
        [
         "Location",
         "",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Owner",
         "pamujulasainadh2001@gmail.com",
         ""
        ],
        [
         "Is_managed_location",
         "true",
         ""
        ],
        [
         "Predictive Optimization",
         "ENABLE (inherited from METASTORE metastore_aws_us_east_2)",
         ""
        ],
        [
         "Table Properties",
         "[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]",
         ""
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 9
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe table extended parquet_bronze_ctas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dde26187-dee7-4a0a-a1d6-ab0b0e68d5bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th></tr></thead><tbody><tr><td>1</td><td>Amanda</td><td>Jordan</td><td>ajordan0@com.com</td><td>Female</td><td>null</td><td>6759521864920116</td><td>Indonesia</td><td>3/8/1971</td><td>49756.53</td><td>Internal Auditor</td><td>1E+02</td></tr><tr><td>2</td><td>Albert</td><td>Freeman</td><td>afreeman1@is.gd</td><td>Male</td><td>218.111.175.34</td><td></td><td>Canada</td><td>1/16/1968</td><td>150280.17</td><td>Accountant IV</td><td></td></tr><tr><td>3</td><td>Evelyn</td><td>Morgan</td><td>emorgan2@altervista.org</td><td>Female</td><td>7.161.136.94</td><td>6767119071901597</td><td>Russia</td><td>2/1/1960</td><td>144972.51</td><td>Structural Engineer</td><td></td></tr><tr><td>4</td><td>Denise</td><td>Riley</td><td>driley3@gmpg.org</td><td>Female</td><td>140.35.109.83</td><td>3576031598965625</td><td>China</td><td>4/8/1997</td><td>90263.05</td><td>Senior Cost Accountant</td><td></td></tr><tr><td>5</td><td>Carlos</td><td>Burns</td><td>cburns4@miitbeian.gov.cn</td><td></td><td>169.113.235.40</td><td>5602256255204850</td><td>South Africa</td><td></td><td>null</td><td></td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Amanda",
         "Jordan",
         "ajordan0@com.com",
         "Female",
         null,
         "6759521864920116",
         "Indonesia",
         "3/8/1971",
         49756.53,
         "Internal Auditor",
         "1E+02"
        ],
        [
         2,
         "Albert",
         "Freeman",
         "afreeman1@is.gd",
         "Male",
         "218.111.175.34",
         "",
         "Canada",
         "1/16/1968",
         150280.17,
         "Accountant IV",
         ""
        ],
        [
         3,
         "Evelyn",
         "Morgan",
         "emorgan2@altervista.org",
         "Female",
         "7.161.136.94",
         "6767119071901597",
         "Russia",
         "2/1/1960",
         144972.51,
         "Structural Engineer",
         ""
        ],
        [
         4,
         "Denise",
         "Riley",
         "driley3@gmpg.org",
         "Female",
         "140.35.109.83",
         "3576031598965625",
         "China",
         "4/8/1997",
         90263.05,
         "Senior Cost Accountant",
         ""
        ],
        [
         5,
         "Carlos",
         "Burns",
         "cburns4@miitbeian.gov.cn",
         "",
         "169.113.235.40",
         "5602256255204850",
         "South Africa",
         "",
         null,
         "",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "# Data Batch Ingestion with Python\n",
    "# read parquet files in spark df\n",
    "df = spark.read.format('parquet').load('/Volumes/workspace/v01/parquet')\n",
    "# write the df to a delta table\n",
    "df.write.mode('overwrite').saveAsTable('workspace.default.parquet_bronze_python')\n",
    "# read and view the table\n",
    "parque_bronze_table=spark.table('workspace.default.parquet_bronze_python')\n",
    "parque_bronze_table.limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffef13f9-722d-420f-bee0-4b4e769655fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Incremental ingestion using copy into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea5d098a-c9c8-4777-98e9-347372a5e319",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8477624649487226>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_cell_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msql\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-- copy into schema mismatch\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-- This will throw an error because there\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms mimatch between the schema of the table and the schema of the parquet data \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mdrop table if exists parquet_bronze_ci;\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-- create an empty table with specified schema\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mcreate table parquet_bronze_ci(\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  first_name string,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  last_name string\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m);\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-- use copy into to populate delta table\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mcopy into parquet_bronze_ci\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfrom \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Volumes/workspace/v01/parquet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfileformat = parquet;\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n",
       "\u001B[1;32m   2539\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n",
       "\u001B[1;32m   2540\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n",
       "\u001B[0;32m-> 2541\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m   2543\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n",
       "\u001B[1;32m   2544\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n",
       "\u001B[1;32m   2545\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n",
       "\u001B[1;32m   2546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:147\u001B[0m, in \u001B[0;36mSqlMagic.sql\u001B[0;34m(self, line, cell)\u001B[0m\n",
       "\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m    144\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot run \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124mql command because spark connect initialization failed and no stacktrace was available.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    145\u001B[0m     )\n",
       "\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_py4j:\n",
       "\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_py4j(cell)\n",
       "\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_sql_comm_handler(cell)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:231\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n",
       "\u001B[0;32m--> 231\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
       "\u001B[1;32m    232\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_SUCCEEDED\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:227\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n",
       "\u001B[1;32m    225\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuting subquery: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery_text\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39m__stdout__)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
       "\u001B[1;32m    226\u001B[0m         sql_directive \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetSqlDirective(query_text)\n",
       "\u001B[0;32m--> 227\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_sql_directive(sql_directive, i \u001B[38;5;241m==\u001B[39m number_of_sub_queries \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:249\u001B[0m, in \u001B[0;36mSqlMagic.handle_sql_directive\u001B[0;34m(self, sql_directive, is_last_query)\u001B[0m\n",
       "\u001B[1;32m    247\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSELECT * FROM \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtable_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m directive_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNoDirective\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[0;32m--> 249\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(sql_directive\u001B[38;5;241m.\u001B[39msql())\n",
       "\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(df\u001B[38;5;241m.\u001B[39mschema) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m    251\u001B[0m         \u001B[38;5;66;03m# E.g. \"create or replace temp view abc as select 1\" gets us here and we should not return a result in this case.\u001B[39;00m\n",
       "\u001B[1;32m    252\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:124\u001B[0m, in \u001B[0;36mSqlMagic.get_query_request_result\u001B[0;34m(self, query)\u001B[0m\n",
       "\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(widget_bindings \u001B[38;5;241m:=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mgetAll()) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPARAM_SYNTAX_USAGE\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m--> 124\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masserting_spark\u001B[38;5;241m.\u001B[39msql(query, widget_bindings)\n",
       "\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/session.py:736\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    733\u001B[0m         _views\u001B[38;5;241m.\u001B[39mappend(SubqueryAlias(df\u001B[38;5;241m.\u001B[39m_plan, name))\n",
       "\u001B[1;32m    735\u001B[0m cmd \u001B[38;5;241m=\u001B[39m SQL(sqlQuery, _args, _named_args, _views)\n",
       "\u001B[0;32m--> 736\u001B[0m data, properties, ei \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mexecute_command(cmd\u001B[38;5;241m.\u001B[39mcommand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client))\n",
       "\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m properties:\n",
       "\u001B[1;32m    738\u001B[0m     df \u001B[38;5;241m=\u001B[39m DataFrame(CachedRelation(properties[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m]), \u001B[38;5;28mself\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1297\u001B[0m, in \u001B[0;36mSparkConnectClient.execute_command\u001B[0;34m(self, command, observations, extra_request_metadata)\u001B[0m\n",
       "\u001B[1;32m   1295\u001B[0m     req\u001B[38;5;241m.\u001B[39muser_context\u001B[38;5;241m.\u001B[39muser_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_user_id\n",
       "\u001B[1;32m   1296\u001B[0m req\u001B[38;5;241m.\u001B[39mplan\u001B[38;5;241m.\u001B[39mcommand\u001B[38;5;241m.\u001B[39mCopyFrom(command)\n",
       "\u001B[0;32m-> 1297\u001B[0m data, _, metrics, observed_metrics, properties \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch(\n",
       "\u001B[1;32m   1298\u001B[0m     req, observations \u001B[38;5;129;01mor\u001B[39;00m {}, extra_request_metadata\n",
       "\u001B[1;32m   1299\u001B[0m )\n",
       "\u001B[1;32m   1300\u001B[0m \u001B[38;5;66;03m# Create a query execution object.\u001B[39;00m\n",
       "\u001B[1;32m   1301\u001B[0m ei \u001B[38;5;241m=\u001B[39m ExecutionInfo(metrics, observed_metrics)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1755\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch\u001B[0;34m(self, req, observations, extra_request_metadata, self_destruct)\u001B[0m\n",
       "\u001B[1;32m   1752\u001B[0m properties: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n",
       "\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Progress(handlers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_progress_handlers, operation_id\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39moperation_id) \u001B[38;5;28;01mas\u001B[39;00m progress:\n",
       "\u001B[0;32m-> 1755\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m response \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch_as_iterator(\n",
       "\u001B[1;32m   1756\u001B[0m         req, observations, extra_request_metadata \u001B[38;5;129;01mor\u001B[39;00m [], progress\u001B[38;5;241m=\u001B[39mprogress\n",
       "\u001B[1;32m   1757\u001B[0m     ):\n",
       "\u001B[1;32m   1758\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, StructType):\n",
       "\u001B[1;32m   1759\u001B[0m             schema \u001B[38;5;241m=\u001B[39m response\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1731\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001B[0;34m(self, req, observations, extra_request_metadata, progress)\u001B[0m\n",
       "\u001B[1;32m   1729\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m kb\n",
       "\u001B[1;32m   1730\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n",
       "\u001B[0;32m-> 1731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_error(error)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2047\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_error\u001B[0;34m(self, error)\u001B[0m\n",
       "\u001B[1;32m   2045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthread_local\u001B[38;5;241m.\u001B[39minside_error_handling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, grpc\u001B[38;5;241m.\u001B[39mRpcError):\n",
       "\u001B[0;32m-> 2047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_rpc_error(error)\n",
       "\u001B[1;32m   2048\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
       "\u001B[1;32m   2049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke RPC\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2149\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_rpc_error\u001B[0;34m(self, rpc_error)\u001B[0m\n",
       "\u001B[1;32m   2134\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m   2135\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython versions in the Spark Connect client and server are different. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   2136\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo execute user-defined functions, client and server should have the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   2145\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.databricks.com/en/release-notes/serverless.html.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   2146\u001B[0m                 )\n",
       "\u001B[1;32m   2147\u001B[0m             \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n",
       "\u001B[0;32m-> 2149\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m convert_exception(\n",
       "\u001B[1;32m   2150\u001B[0m                 info,\n",
       "\u001B[1;32m   2151\u001B[0m                 status\u001B[38;5;241m.\u001B[39mmessage,\n",
       "\u001B[1;32m   2152\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetch_enriched_error(info),\n",
       "\u001B[1;32m   2153\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_server_stack_trace(),\n",
       "\u001B[1;32m   2154\u001B[0m             ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   2156\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(status\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   2157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [COPY_INTO_SCHEMA_MISMATCH_WITH_TARGET_TABLE] A schema mismatch was detected while copying into the Delta table (Table: `workspace`.`default`.`parquet_bronze_ci`).\n",
       "This may indicate an issue with the incoming data, or the Delta table schema can be evolved automatically according to the incoming data by setting:\n",
       "COPY_OPTIONS ('mergeSchema' = 'true')\n",
       "\n",
       "Schema difference:\n",
       "Incoming schema has additional field(s): email, country, salary, birthdate, id, ip_address, cc, title, comments, gender\n",
       "\n",
       "\n",
       "JVM stacktrace:\n",
       "com.databricks.sql.transaction.tahoe.DeltaAnalysisException\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable(DeltaErrorsEdge.scala:542)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable$(DeltaErrorsEdge.scala:529)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.copyIntoSchemaMismatchWithTargetTable(DeltaErrors.scala:3952)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$2(CopyIntoCommandEdge.scala:554)\n",
       "\tat com.databricks.sql.acl.fs.TemporaryCredentialsHelper$.withTemporaryCredentials(FixedCredentialsFileSystem.scala:670)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.$anonfun$withTemporaryCredentials$1(CopyIntoCommandEdge.scala:1085)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.convertExceptions(CopyIntoCommandEdge.scala:1054)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.withTemporaryCredentials(CopyIntoCommandEdge.scala:1084)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$1(CopyIntoCommandEdge.scala:508)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n",
       "\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.run(CopyIntoCommandEdge.scala:507)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:441)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:441)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:440)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n",
       "\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:436)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1299)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:432)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:369)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:430)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:494)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:489)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:489)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:489)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:325)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1683)\n",
       "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1744)\n",
       "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:330)\n",
       "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n",
       "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n",
       "\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n",
       "\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:240)\n",
       "\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
       "\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n",
       "\tat scala.util.Using$.resource(Using.scala:269)\n",
       "\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[COPY_INTO_SCHEMA_MISMATCH_WITH_TARGET_TABLE] A schema mismatch was detected while copying into the Delta table (Table: `workspace`.`default`.`parquet_bronze_ci`).\nThis may indicate an issue with the incoming data, or the Delta table schema can be evolved automatically according to the incoming data by setting:\nCOPY_OPTIONS ('mergeSchema' = 'true')\n\nSchema difference:\nIncoming schema has additional field(s): email, country, salary, birthdate, id, ip_address, cc, title, comments, gender\n\n\nJVM stacktrace:\ncom.databricks.sql.transaction.tahoe.DeltaAnalysisException\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable(DeltaErrorsEdge.scala:542)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable$(DeltaErrorsEdge.scala:529)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.copyIntoSchemaMismatchWithTargetTable(DeltaErrors.scala:3952)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$2(CopyIntoCommandEdge.scala:554)\n\tat com.databricks.sql.acl.fs.TemporaryCredentialsHelper$.withTemporaryCredentials(FixedCredentialsFileSystem.scala:670)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.$anonfun$withTemporaryCredentials$1(CopyIntoCommandEdge.scala:1085)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.convertExceptions(CopyIntoCommandEdge.scala:1054)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.withTemporaryCredentials(CopyIntoCommandEdge.scala:1084)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$1(CopyIntoCommandEdge.scala:508)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.run(CopyIntoCommandEdge.scala:507)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:441)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:441)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:440)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1299)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:432)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:369)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:430)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:494)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:489)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:489)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:489)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:325)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1683)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1744)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:330)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:240)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
       },
       "metadata": {
        "errorSummary": "[COPY_INTO_SCHEMA_MISMATCH_WITH_TARGET_TABLE] A schema mismatch was detected while copying into the Delta table (Table: `workspace`.`default`.`parquet_bronze_ci`).\nThis may indicate an issue with the incoming data, or the Delta table schema can be evolved automatically according to the incoming data by setting:\nCOPY_OPTIONS ('mergeSchema' = 'true')\n\nSchema difference:\nIncoming schema has additional field(s): email, country, salary, birthdate, id, ip_address, cc, title, comments, gender\n SQLSTATE: 42KDG"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "COPY_INTO_SCHEMA_MISMATCH_WITH_TARGET_TABLE",
        "pysparkCallSite": "",
        "pysparkFragment": "",
        "pysparkSummary": null,
        "sqlState": "42KDG",
        "stackTrace": "com.databricks.sql.transaction.tahoe.DeltaAnalysisException\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable(DeltaErrorsEdge.scala:542)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable$(DeltaErrorsEdge.scala:529)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.copyIntoSchemaMismatchWithTargetTable(DeltaErrors.scala:3952)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$2(CopyIntoCommandEdge.scala:554)\n\tat com.databricks.sql.acl.fs.TemporaryCredentialsHelper$.withTemporaryCredentials(FixedCredentialsFileSystem.scala:670)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.$anonfun$withTemporaryCredentials$1(CopyIntoCommandEdge.scala:1085)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.convertExceptions(CopyIntoCommandEdge.scala:1054)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.withTemporaryCredentials(CopyIntoCommandEdge.scala:1084)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$1(CopyIntoCommandEdge.scala:508)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.run(CopyIntoCommandEdge.scala:507)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:441)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:441)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:440)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1299)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:432)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:369)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:430)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:494)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:489)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:489)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:489)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:325)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1683)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1744)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:330)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:240)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-8477624649487226>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_cell_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msql\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-- copy into schema mismatch\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-- This will throw an error because there\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms mimatch between the schema of the table and the schema of the parquet data \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mdrop table if exists parquet_bronze_ci;\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-- create an empty table with specified schema\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mcreate table parquet_bronze_ci(\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  first_name string,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  last_name string\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m);\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-- use copy into to populate delta table\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mcopy into parquet_bronze_ci\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfrom \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Volumes/workspace/v01/parquet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfileformat = parquet;\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2539\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2540\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2541\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   2543\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2544\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2545\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:147\u001B[0m, in \u001B[0;36mSqlMagic.sql\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot run \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124mql command because spark connect initialization failed and no stacktrace was available.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    145\u001B[0m     )\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_py4j:\n\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_py4j(cell)\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_sql_comm_handler(cell)\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:231\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n\u001B[0;32m--> 231\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_SUCCEEDED\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:227\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuting subquery: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery_text\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39m__stdout__)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    226\u001B[0m         sql_directive \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetSqlDirective(query_text)\n\u001B[0;32m--> 227\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_sql_directive(sql_directive, i \u001B[38;5;241m==\u001B[39m number_of_sub_queries \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:249\u001B[0m, in \u001B[0;36mSqlMagic.handle_sql_directive\u001B[0;34m(self, sql_directive, is_last_query)\u001B[0m\n\u001B[1;32m    247\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSELECT * FROM \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtable_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m directive_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNoDirective\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 249\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(sql_directive\u001B[38;5;241m.\u001B[39msql())\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(df\u001B[38;5;241m.\u001B[39mschema) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    251\u001B[0m         \u001B[38;5;66;03m# E.g. \"create or replace temp view abc as select 1\" gets us here and we should not return a result in this case.\u001B[39;00m\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:124\u001B[0m, in \u001B[0;36mSqlMagic.get_query_request_result\u001B[0;34m(self, query)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(widget_bindings \u001B[38;5;241m:=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mgetAll()) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPARAM_SYNTAX_USAGE\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 124\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masserting_spark\u001B[38;5;241m.\u001B[39msql(query, widget_bindings)\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/session.py:736\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m    733\u001B[0m         _views\u001B[38;5;241m.\u001B[39mappend(SubqueryAlias(df\u001B[38;5;241m.\u001B[39m_plan, name))\n\u001B[1;32m    735\u001B[0m cmd \u001B[38;5;241m=\u001B[39m SQL(sqlQuery, _args, _named_args, _views)\n\u001B[0;32m--> 736\u001B[0m data, properties, ei \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mexecute_command(cmd\u001B[38;5;241m.\u001B[39mcommand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client))\n\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m properties:\n\u001B[1;32m    738\u001B[0m     df \u001B[38;5;241m=\u001B[39m DataFrame(CachedRelation(properties[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m]), \u001B[38;5;28mself\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1297\u001B[0m, in \u001B[0;36mSparkConnectClient.execute_command\u001B[0;34m(self, command, observations, extra_request_metadata)\u001B[0m\n\u001B[1;32m   1295\u001B[0m     req\u001B[38;5;241m.\u001B[39muser_context\u001B[38;5;241m.\u001B[39muser_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_user_id\n\u001B[1;32m   1296\u001B[0m req\u001B[38;5;241m.\u001B[39mplan\u001B[38;5;241m.\u001B[39mcommand\u001B[38;5;241m.\u001B[39mCopyFrom(command)\n\u001B[0;32m-> 1297\u001B[0m data, _, metrics, observed_metrics, properties \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch(\n\u001B[1;32m   1298\u001B[0m     req, observations \u001B[38;5;129;01mor\u001B[39;00m {}, extra_request_metadata\n\u001B[1;32m   1299\u001B[0m )\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;66;03m# Create a query execution object.\u001B[39;00m\n\u001B[1;32m   1301\u001B[0m ei \u001B[38;5;241m=\u001B[39m ExecutionInfo(metrics, observed_metrics)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1755\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch\u001B[0;34m(self, req, observations, extra_request_metadata, self_destruct)\u001B[0m\n\u001B[1;32m   1752\u001B[0m properties: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Progress(handlers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_progress_handlers, operation_id\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39moperation_id) \u001B[38;5;28;01mas\u001B[39;00m progress:\n\u001B[0;32m-> 1755\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m response \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch_as_iterator(\n\u001B[1;32m   1756\u001B[0m         req, observations, extra_request_metadata \u001B[38;5;129;01mor\u001B[39;00m [], progress\u001B[38;5;241m=\u001B[39mprogress\n\u001B[1;32m   1757\u001B[0m     ):\n\u001B[1;32m   1758\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, StructType):\n\u001B[1;32m   1759\u001B[0m             schema \u001B[38;5;241m=\u001B[39m response\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1731\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001B[0;34m(self, req, observations, extra_request_metadata, progress)\u001B[0m\n\u001B[1;32m   1729\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m kb\n\u001B[1;32m   1730\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[0;32m-> 1731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_error(error)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2047\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_error\u001B[0;34m(self, error)\u001B[0m\n\u001B[1;32m   2045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthread_local\u001B[38;5;241m.\u001B[39minside_error_handling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, grpc\u001B[38;5;241m.\u001B[39mRpcError):\n\u001B[0;32m-> 2047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_rpc_error(error)\n\u001B[1;32m   2048\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   2049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke RPC\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2149\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_rpc_error\u001B[0;34m(self, rpc_error)\u001B[0m\n\u001B[1;32m   2134\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m   2135\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython versions in the Spark Connect client and server are different. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2136\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo execute user-defined functions, client and server should have the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2145\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.databricks.com/en/release-notes/serverless.html.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2146\u001B[0m                 )\n\u001B[1;32m   2147\u001B[0m             \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n\u001B[0;32m-> 2149\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m convert_exception(\n\u001B[1;32m   2150\u001B[0m                 info,\n\u001B[1;32m   2151\u001B[0m                 status\u001B[38;5;241m.\u001B[39mmessage,\n\u001B[1;32m   2152\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetch_enriched_error(info),\n\u001B[1;32m   2153\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_server_stack_trace(),\n\u001B[1;32m   2154\u001B[0m             ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2156\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(status\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [COPY_INTO_SCHEMA_MISMATCH_WITH_TARGET_TABLE] A schema mismatch was detected while copying into the Delta table (Table: `workspace`.`default`.`parquet_bronze_ci`).\nThis may indicate an issue with the incoming data, or the Delta table schema can be evolved automatically according to the incoming data by setting:\nCOPY_OPTIONS ('mergeSchema' = 'true')\n\nSchema difference:\nIncoming schema has additional field(s): email, country, salary, birthdate, id, ip_address, cc, title, comments, gender\n\n\nJVM stacktrace:\ncom.databricks.sql.transaction.tahoe.DeltaAnalysisException\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable(DeltaErrorsEdge.scala:542)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsEdge.copyIntoSchemaMismatchWithTargetTable$(DeltaErrorsEdge.scala:529)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.copyIntoSchemaMismatchWithTargetTable(DeltaErrors.scala:3952)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$2(CopyIntoCommandEdge.scala:554)\n\tat com.databricks.sql.acl.fs.TemporaryCredentialsHelper$.withTemporaryCredentials(FixedCredentialsFileSystem.scala:670)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.$anonfun$withTemporaryCredentials$1(CopyIntoCommandEdge.scala:1085)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.convertExceptions(CopyIntoCommandEdge.scala:1054)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge$.withTemporaryCredentials(CopyIntoCommandEdge.scala:1084)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.$anonfun$run$1(CopyIntoCommandEdge.scala:508)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n\tat com.databricks.sql.transaction.tahoe.commands.copy.CopyIntoCommandEdge.run(CopyIntoCommandEdge.scala:507)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:441)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:441)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:440)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1299)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:432)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:369)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:430)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:494)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:489)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:489)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:489)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:325)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1683)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1744)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:330)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:240)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- copy into schema mismatch\n",
    "-- This will throw an error because there's mimatch between the schema of the table and the schema of the parquet data \n",
    "drop table if exists parquet_bronze_ci;\n",
    "-- create an empty table with specified schema\n",
    "create table parquet_bronze_ci(\n",
    "  first_name string,\n",
    "  last_name string\n",
    ");\n",
    "-- use copy into to populate delta table\n",
    "copy into parquet_bronze_ci\n",
    "from '/Volumes/workspace/v01/parquet'\n",
    "fileformat = parquet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36a5d841-b025-4192-8157-fc13902d1a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th><th>num_skipped_corrupt_files</th></tr></thead><tbody><tr><td>3000</td><td>3000</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3000,
         3000,
         0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_skipped_corrupt_files",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 44
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_skipped_corrupt_files",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- we can resolve the above error with merge schema=True\n",
    "copy into parquet_bronze_ci\n",
    "from '/Volumes/workspace/v01/parquet'\n",
    "fileformat = parquet\n",
    "copy_options('mergeSchema' = 'true');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b30ea280-374c-42e5-be6a-fc98878cc171",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>first_name</th><th>last_name</th><th>id</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th></tr></thead><tbody><tr><td>Amanda</td><td>Jordan</td><td>1</td><td>ajordan0@com.com</td><td>Female</td><td>null</td><td>6759521864920116</td><td>Indonesia</td><td>3/8/1971</td><td>49756.53</td><td>Internal Auditor</td><td>1E+02</td></tr><tr><td>Albert</td><td>Freeman</td><td>2</td><td>afreeman1@is.gd</td><td>Male</td><td>218.111.175.34</td><td></td><td>Canada</td><td>1/16/1968</td><td>150280.17</td><td>Accountant IV</td><td></td></tr><tr><td>Evelyn</td><td>Morgan</td><td>3</td><td>emorgan2@altervista.org</td><td>Female</td><td>7.161.136.94</td><td>6767119071901597</td><td>Russia</td><td>2/1/1960</td><td>144972.51</td><td>Structural Engineer</td><td></td></tr><tr><td>Denise</td><td>Riley</td><td>4</td><td>driley3@gmpg.org</td><td>Female</td><td>140.35.109.83</td><td>3576031598965625</td><td>China</td><td>4/8/1997</td><td>90263.05</td><td>Senior Cost Accountant</td><td></td></tr><tr><td>Carlos</td><td>Burns</td><td>5</td><td>cburns4@miitbeian.gov.cn</td><td></td><td>169.113.235.40</td><td>5602256255204850</td><td>South Africa</td><td></td><td>null</td><td></td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Amanda",
         "Jordan",
         1,
         "ajordan0@com.com",
         "Female",
         null,
         "6759521864920116",
         "Indonesia",
         "3/8/1971",
         49756.53,
         "Internal Auditor",
         "1E+02"
        ],
        [
         "Albert",
         "Freeman",
         2,
         "afreeman1@is.gd",
         "Male",
         "218.111.175.34",
         "",
         "Canada",
         "1/16/1968",
         150280.17,
         "Accountant IV",
         ""
        ],
        [
         "Evelyn",
         "Morgan",
         3,
         "emorgan2@altervista.org",
         "Female",
         "7.161.136.94",
         "6767119071901597",
         "Russia",
         "2/1/1960",
         144972.51,
         "Structural Engineer",
         ""
        ],
        [
         "Denise",
         "Riley",
         4,
         "driley3@gmpg.org",
         "Female",
         "140.35.109.83",
         "3576031598965625",
         "China",
         "4/8/1997",
         90263.05,
         "Senior Cost Accountant",
         ""
        ],
        [
         "Carlos",
         "Burns",
         5,
         "cburns4@miitbeian.gov.cn",
         "",
         "169.113.235.40",
         "5602256255204850",
         "South Africa",
         "",
         null,
         "",
         ""
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 55
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "select *\n",
    "from parquet_bronze_ci\n",
    "limit 5;\n",
    "-- note what's the order we've created in the first time the same order it'll merge the final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34bef647-aea7-4559-b3df-c8df4004369f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th><th>num_skipped_corrupt_files</th></tr></thead><tbody><tr><td>3000</td><td>3000</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3000,
         3000,
         0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_skipped_corrupt_files",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 50
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_skipped_corrupt_files",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- we can also create with empty table first and merge the schema\n",
    "drop table if exists parquet_bronze_ci_no_schema;\n",
    "\n",
    "create table parquet_bronze_ci_no_schema;\n",
    "\n",
    "copy into parquet_bronze_ci_no_schema\n",
    "  from '/Volumes/workspace/v01/parquet'\n",
    "  fileformat = parquet\n",
    "  copy_options('mergeschema'='true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cc39bc3-4acf-424d-a36f-36fd2cc1872e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th></tr></thead><tbody><tr><td>1</td><td>Amanda</td><td>Jordan</td><td>ajordan0@com.com</td><td>Female</td><td>null</td><td>6759521864920116</td><td>Indonesia</td><td>3/8/1971</td><td>49756.53</td><td>Internal Auditor</td><td>1E+02</td></tr><tr><td>2</td><td>Albert</td><td>Freeman</td><td>afreeman1@is.gd</td><td>Male</td><td>218.111.175.34</td><td></td><td>Canada</td><td>1/16/1968</td><td>150280.17</td><td>Accountant IV</td><td></td></tr><tr><td>3</td><td>Evelyn</td><td>Morgan</td><td>emorgan2@altervista.org</td><td>Female</td><td>7.161.136.94</td><td>6767119071901597</td><td>Russia</td><td>2/1/1960</td><td>144972.51</td><td>Structural Engineer</td><td></td></tr><tr><td>4</td><td>Denise</td><td>Riley</td><td>driley3@gmpg.org</td><td>Female</td><td>140.35.109.83</td><td>3576031598965625</td><td>China</td><td>4/8/1997</td><td>90263.05</td><td>Senior Cost Accountant</td><td></td></tr><tr><td>5</td><td>Carlos</td><td>Burns</td><td>cburns4@miitbeian.gov.cn</td><td></td><td>169.113.235.40</td><td>5602256255204850</td><td>South Africa</td><td></td><td>null</td><td></td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Amanda",
         "Jordan",
         "ajordan0@com.com",
         "Female",
         null,
         "6759521864920116",
         "Indonesia",
         "3/8/1971",
         49756.53,
         "Internal Auditor",
         "1E+02"
        ],
        [
         2,
         "Albert",
         "Freeman",
         "afreeman1@is.gd",
         "Male",
         "218.111.175.34",
         "",
         "Canada",
         "1/16/1968",
         150280.17,
         "Accountant IV",
         ""
        ],
        [
         3,
         "Evelyn",
         "Morgan",
         "emorgan2@altervista.org",
         "Female",
         "7.161.136.94",
         "6767119071901597",
         "Russia",
         "2/1/1960",
         144972.51,
         "Structural Engineer",
         ""
        ],
        [
         4,
         "Denise",
         "Riley",
         "driley3@gmpg.org",
         "Female",
         "140.35.109.83",
         "3576031598965625",
         "China",
         "4/8/1997",
         90263.05,
         "Senior Cost Accountant",
         ""
        ],
        [
         5,
         "Carlos",
         "Burns",
         "cburns4@miitbeian.gov.cn",
         "",
         "169.113.235.40",
         "5602256255204850",
         "South Africa",
         "",
         null,
         "",
         ""
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 54
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "select *\n",
    "  from parquet_bronze_ci_no_schema\n",
    "  limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77769353-6c1f-405f-ad31-312a4f97936d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th><th>num_skipped_corrupt_files</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_skipped_corrupt_files",
            "nullable": true,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 53
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_skipped_corrupt_files",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "--to check the idempotentency\n",
    "-- as this is the incremental already all files are already loaded it won't load anything\n",
    "copy into parquet_bronze_ci_no_schema\n",
    "  from '/Volumes/workspace/v01/parquet'\n",
    "  fileformat = parquet\n",
    "  copy_options('mergeschema'='true');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dbee05a-47d0-43a6-b5b8-5db957290bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Adding metadata during ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5941be36-e824-47fd-95da-06956acc0e15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th><th>_rescued_data</th><th>cc_num</th></tr></thead><tbody><tr><td>1</td><td>Kelly</td><td>Ortiz</td><td>kortiz0@omniture.com</td><td>Female</td><td>252.115.158.159</td><td>3537905681760845</td><td>Russia</td><td>4/23/1980</td><td>277302.99</td><td>Nurse</td><td></td><td>null</td><td>3537905681760845</td></tr><tr><td>2</td><td>Sharon</td><td>Carroll</td><td>scarroll1@disqus.com</td><td>Female</td><td>29.217.252.62</td><td>56022458507191696</td><td>Indonesia</td><td>8/28/1992</td><td>209258.05</td><td>Recruiter</td><td>åß∂ƒ©˙∆˚¬…æ</td><td>null</td><td>56022458507191696</td></tr><tr><td>3</td><td>Ruth</td><td>Ross</td><td>rross2@cbc.ca</td><td>Female</td><td>220.224.80.32</td><td>3589642396435648</td><td>Benin</td><td>6/13/1994</td><td>18270.7</td><td>Design Engineer</td><td></td><td>null</td><td>3589642396435648</td></tr><tr><td>4</td><td>Kelly</td><td>Meyer</td><td>kmeyer3@cornell.edu</td><td>Female</td><td>255.65.123.124</td><td></td><td>Philippines</td><td>1/6/1967</td><td>17485.27</td><td>Cost Accountant</td><td></td><td>null</td><td>null</td></tr><tr><td>5</td><td>Irene</td><td>Jordan</td><td>ijordan4@pagesperso-orange.fr</td><td>Female</td><td>162.57.23.136</td><td>3576848317807089</td><td>United States</td><td>1/4/1997</td><td>163979.38</td><td>Programmer Analyst III</td><td></td><td>null</td><td>3576848317807089</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Kelly",
         "Ortiz",
         "kortiz0@omniture.com",
         "Female",
         "252.115.158.159",
         "3537905681760845",
         "Russia",
         "4/23/1980",
         277302.99,
         "Nurse",
         "",
         null,
         3537905681760845
        ],
        [
         2,
         "Sharon",
         "Carroll",
         "scarroll1@disqus.com",
         "Female",
         "29.217.252.62",
         "56022458507191696",
         "Indonesia",
         "8/28/1992",
         209258.05,
         "Recruiter",
         "åß∂ƒ©˙∆˚¬…æ",
         null,
         56022458507191696
        ],
        [
         3,
         "Ruth",
         "Ross",
         "rross2@cbc.ca",
         "Female",
         "220.224.80.32",
         "3589642396435648",
         "Benin",
         "6/13/1994",
         18270.7,
         "Design Engineer",
         "",
         null,
         3589642396435648
        ],
        [
         4,
         "Kelly",
         "Meyer",
         "kmeyer3@cornell.edu",
         "Female",
         "255.65.123.124",
         "",
         "Philippines",
         "1/6/1967",
         17485.27,
         "Cost Accountant",
         "",
         null,
         null
        ],
        [
         5,
         "Irene",
         "Jordan",
         "ijordan4@pagesperso-orange.fr",
         "Female",
         "162.57.23.136",
         "3576848317807089",
         "United States",
         "1/4/1997",
         163979.38,
         "Programmer Analyst III",
         "",
         null,
         3576848317807089
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc_num",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 76
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc_num",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- altering the data type of a column while reading the files in a volume\n",
    "select *,try_cast(cc as bigint) as cc_num\n",
    "from read_files('/Volumes/workspace/v01/parquet',format=> 'parquet')\n",
    "limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e80ebdfb-a45d-4f1b-b3a2-10bc2710ee0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th><th>_rescued_data</th><th>cc_num</th><th>cc_date</th></tr></thead><tbody><tr><td>1</td><td>Kelly</td><td>Ortiz</td><td>kortiz0@omniture.com</td><td>Female</td><td>252.115.158.159</td><td>3537905681760845</td><td>Russia</td><td>4/23/1980</td><td>277302.99</td><td>Nurse</td><td></td><td>null</td><td>3537905681760845</td><td>2082-02-09</td></tr><tr><td>2</td><td>Sharon</td><td>Carroll</td><td>scarroll1@disqus.com</td><td>Female</td><td>29.217.252.62</td><td>56022458507191696</td><td>Indonesia</td><td>8/28/1992</td><td>209258.05</td><td>Recruiter</td><td>åß∂ƒ©˙∆˚¬…æ</td><td>null</td><td>56022458507191696</td><td>3745-04-13</td></tr><tr><td>3</td><td>Ruth</td><td>Ross</td><td>rross2@cbc.ca</td><td>Female</td><td>220.224.80.32</td><td>3589642396435648</td><td>Benin</td><td>6/13/1994</td><td>18270.7</td><td>Design Engineer</td><td></td><td>null</td><td>3589642396435648</td><td>2083-10-01</td></tr><tr><td>4</td><td>Kelly</td><td>Meyer</td><td>kmeyer3@cornell.edu</td><td>Female</td><td>255.65.123.124</td><td></td><td>Philippines</td><td>1/6/1967</td><td>17485.27</td><td>Cost Accountant</td><td></td><td>null</td><td>null</td><td>null</td></tr><tr><td>5</td><td>Irene</td><td>Jordan</td><td>ijordan4@pagesperso-orange.fr</td><td>Female</td><td>162.57.23.136</td><td>3576848317807089</td><td>United States</td><td>1/4/1997</td><td>163979.38</td><td>Programmer Analyst III</td><td></td><td>null</td><td>3576848317807089</td><td>2083-05-06</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Kelly",
         "Ortiz",
         "kortiz0@omniture.com",
         "Female",
         "252.115.158.159",
         "3537905681760845",
         "Russia",
         "4/23/1980",
         277302.99,
         "Nurse",
         "",
         null,
         3537905681760845,
         "2082-02-09"
        ],
        [
         2,
         "Sharon",
         "Carroll",
         "scarroll1@disqus.com",
         "Female",
         "29.217.252.62",
         "56022458507191696",
         "Indonesia",
         "8/28/1992",
         209258.05,
         "Recruiter",
         "åß∂ƒ©˙∆˚¬…æ",
         null,
         56022458507191696,
         "3745-04-13"
        ],
        [
         3,
         "Ruth",
         "Ross",
         "rross2@cbc.ca",
         "Female",
         "220.224.80.32",
         "3589642396435648",
         "Benin",
         "6/13/1994",
         18270.7,
         "Design Engineer",
         "",
         null,
         3589642396435648,
         "2083-10-01"
        ],
        [
         4,
         "Kelly",
         "Meyer",
         "kmeyer3@cornell.edu",
         "Female",
         "255.65.123.124",
         "",
         "Philippines",
         "1/6/1967",
         17485.27,
         "Cost Accountant",
         "",
         null,
         null,
         null
        ],
        [
         5,
         "Irene",
         "Jordan",
         "ijordan4@pagesperso-orange.fr",
         "Female",
         "162.57.23.136",
         "3576848317807089",
         "United States",
         "1/4/1997",
         163979.38,
         "Programmer Analyst III",
         "",
         null,
         3576848317807089,
         "2083-05-06"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc_num",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cc_date",
            "nullable": true,
            "type": "date"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 78
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc_num",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cc_date",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- convert unix timestamp to date\n",
    "select *,try_cast(cc as bigint) as cc_num,cast(from_unixtime(cc_num/1000000) as date) as cc_date\n",
    "from read_files('/Volumes/workspace/v01/parquet',format=> 'parquet')\n",
    "limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f4b8342-e6f8-4fc6-b94a-168021c426df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th><th>_rescued_data</th><th>cc_num</th><th>cc_date</th><th>file_modification_time</th><th>source_file</th><th>ingestion_time</th></tr></thead><tbody><tr><td>1</td><td>Kelly</td><td>Ortiz</td><td>kortiz0@omniture.com</td><td>Female</td><td>252.115.158.159</td><td>3537905681760845</td><td>Russia</td><td>4/23/1980</td><td>277302.99</td><td>Nurse</td><td></td><td>null</td><td>3537905681760845</td><td>2082-02-09</td><td>2025-07-08T15:54:42.000Z</td><td>part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T13:45:09.649Z</td></tr><tr><td>2</td><td>Sharon</td><td>Carroll</td><td>scarroll1@disqus.com</td><td>Female</td><td>29.217.252.62</td><td>56022458507191696</td><td>Indonesia</td><td>8/28/1992</td><td>209258.05</td><td>Recruiter</td><td>åß∂ƒ©˙∆˚¬…æ</td><td>null</td><td>56022458507191696</td><td>3745-04-13</td><td>2025-07-08T15:54:42.000Z</td><td>part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T13:45:09.649Z</td></tr><tr><td>3</td><td>Ruth</td><td>Ross</td><td>rross2@cbc.ca</td><td>Female</td><td>220.224.80.32</td><td>3589642396435648</td><td>Benin</td><td>6/13/1994</td><td>18270.7</td><td>Design Engineer</td><td></td><td>null</td><td>3589642396435648</td><td>2083-10-01</td><td>2025-07-08T15:54:42.000Z</td><td>part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T13:45:09.649Z</td></tr><tr><td>4</td><td>Kelly</td><td>Meyer</td><td>kmeyer3@cornell.edu</td><td>Female</td><td>255.65.123.124</td><td></td><td>Philippines</td><td>1/6/1967</td><td>17485.27</td><td>Cost Accountant</td><td></td><td>null</td><td>null</td><td>null</td><td>2025-07-08T15:54:42.000Z</td><td>part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T13:45:09.649Z</td></tr><tr><td>5</td><td>Irene</td><td>Jordan</td><td>ijordan4@pagesperso-orange.fr</td><td>Female</td><td>162.57.23.136</td><td>3576848317807089</td><td>United States</td><td>1/4/1997</td><td>163979.38</td><td>Programmer Analyst III</td><td></td><td>null</td><td>3576848317807089</td><td>2083-05-06</td><td>2025-07-08T15:54:42.000Z</td><td>part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T13:45:09.649Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Kelly",
         "Ortiz",
         "kortiz0@omniture.com",
         "Female",
         "252.115.158.159",
         "3537905681760845",
         "Russia",
         "4/23/1980",
         277302.99,
         "Nurse",
         "",
         null,
         3537905681760845,
         "2082-02-09",
         "2025-07-08T15:54:42.000Z",
         "part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T13:45:09.649Z"
        ],
        [
         2,
         "Sharon",
         "Carroll",
         "scarroll1@disqus.com",
         "Female",
         "29.217.252.62",
         "56022458507191696",
         "Indonesia",
         "8/28/1992",
         209258.05,
         "Recruiter",
         "åß∂ƒ©˙∆˚¬…æ",
         null,
         56022458507191696,
         "3745-04-13",
         "2025-07-08T15:54:42.000Z",
         "part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T13:45:09.649Z"
        ],
        [
         3,
         "Ruth",
         "Ross",
         "rross2@cbc.ca",
         "Female",
         "220.224.80.32",
         "3589642396435648",
         "Benin",
         "6/13/1994",
         18270.7,
         "Design Engineer",
         "",
         null,
         3589642396435648,
         "2083-10-01",
         "2025-07-08T15:54:42.000Z",
         "part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T13:45:09.649Z"
        ],
        [
         4,
         "Kelly",
         "Meyer",
         "kmeyer3@cornell.edu",
         "Female",
         "255.65.123.124",
         "",
         "Philippines",
         "1/6/1967",
         17485.27,
         "Cost Accountant",
         "",
         null,
         null,
         null,
         "2025-07-08T15:54:42.000Z",
         "part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T13:45:09.649Z"
        ],
        [
         5,
         "Irene",
         "Jordan",
         "ijordan4@pagesperso-orange.fr",
         "Female",
         "162.57.23.136",
         "3576848317807089",
         "United States",
         "1/4/1997",
         163979.38,
         "Programmer Analyst III",
         "",
         null,
         3576848317807089,
         "2083-05-06",
         "2025-07-08T15:54:42.000Z",
         "part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T13:45:09.649Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc_num",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cc_date",
            "nullable": true,
            "type": "date"
           },
           {
            "metadata": {},
            "name": "file_modification_time",
            "nullable": false,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "source_file",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ingestion_time",
            "nullable": false,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 88
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc_num",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cc_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "file_modification_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "source_file",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingestion_time",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- adding column metadata on ingestion\n",
    "select *,\n",
    "  try_cast(cc as bigint) as cc_num,\n",
    "  cast(from_unixtime(cc_num/1000000) as date) as cc_date,\n",
    "  _metadata.file_modification_time as file_modification_time,\n",
    "  _metadata.file_name as source_file,\n",
    "  current_timestamp() as ingestion_time\n",
    "from read_files('/Volumes/workspace/v01/parquet',format=> 'parquet')\n",
    "limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7efdec-d332-40c5-b468-3045e796dca0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>first_name</th><th>last_name</th><th>email</th><th>gender</th><th>ip_address</th><th>cc</th><th>country</th><th>birthdate</th><th>salary</th><th>title</th><th>comments</th><th>_rescued_data</th><th>cc_num</th><th>cc_date</th><th>file_modification_time</th><th>source_file</th><th>ingestion_time</th></tr></thead><tbody><tr><td>1</td><td>Amanda</td><td>Jordan</td><td>ajordan0@com.com</td><td>Female</td><td>null</td><td>6759521864920116</td><td>Indonesia</td><td>3/8/1971</td><td>49756.53</td><td>Internal Auditor</td><td>1E+02</td><td>null</td><td>6759521864920116</td><td>2184-03-14</td><td>2025-07-08T15:54:42.000Z</td><td>part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T14:57:39.759Z</td></tr><tr><td>2</td><td>Albert</td><td>Freeman</td><td>afreeman1@is.gd</td><td>Male</td><td>218.111.175.34</td><td></td><td>Canada</td><td>1/16/1968</td><td>150280.17</td><td>Accountant IV</td><td></td><td>null</td><td>null</td><td>null</td><td>2025-07-08T15:54:42.000Z</td><td>part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T14:57:39.759Z</td></tr><tr><td>3</td><td>Evelyn</td><td>Morgan</td><td>emorgan2@altervista.org</td><td>Female</td><td>7.161.136.94</td><td>6767119071901597</td><td>Russia</td><td>2/1/1960</td><td>144972.51</td><td>Structural Engineer</td><td></td><td>null</td><td>6767119071901597</td><td>2184-06-10</td><td>2025-07-08T15:54:42.000Z</td><td>part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T14:57:39.759Z</td></tr><tr><td>4</td><td>Denise</td><td>Riley</td><td>driley3@gmpg.org</td><td>Female</td><td>140.35.109.83</td><td>3576031598965625</td><td>China</td><td>4/8/1997</td><td>90263.05</td><td>Senior Cost Accountant</td><td></td><td>null</td><td>3576031598965625</td><td>2083-04-27</td><td>2025-07-08T15:54:42.000Z</td><td>part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T14:57:39.759Z</td></tr><tr><td>5</td><td>Carlos</td><td>Burns</td><td>cburns4@miitbeian.gov.cn</td><td></td><td>169.113.235.40</td><td>5602256255204850</td><td>South Africa</td><td></td><td>null</td><td></td><td></td><td>null</td><td>5602256255204850</td><td>2147-07-12</td><td>2025-07-08T15:54:42.000Z</td><td>part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>2025-07-09T14:57:39.759Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Amanda",
         "Jordan",
         "ajordan0@com.com",
         "Female",
         null,
         "6759521864920116",
         "Indonesia",
         "3/8/1971",
         49756.53,
         "Internal Auditor",
         "1E+02",
         null,
         6759521864920116,
         "2184-03-14",
         "2025-07-08T15:54:42.000Z",
         "part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T14:57:39.759Z"
        ],
        [
         2,
         "Albert",
         "Freeman",
         "afreeman1@is.gd",
         "Male",
         "218.111.175.34",
         "",
         "Canada",
         "1/16/1968",
         150280.17,
         "Accountant IV",
         "",
         null,
         null,
         null,
         "2025-07-08T15:54:42.000Z",
         "part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T14:57:39.759Z"
        ],
        [
         3,
         "Evelyn",
         "Morgan",
         "emorgan2@altervista.org",
         "Female",
         "7.161.136.94",
         "6767119071901597",
         "Russia",
         "2/1/1960",
         144972.51,
         "Structural Engineer",
         "",
         null,
         6767119071901597,
         "2184-06-10",
         "2025-07-08T15:54:42.000Z",
         "part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T14:57:39.759Z"
        ],
        [
         4,
         "Denise",
         "Riley",
         "driley3@gmpg.org",
         "Female",
         "140.35.109.83",
         "3576031598965625",
         "China",
         "4/8/1997",
         90263.05,
         "Senior Cost Accountant",
         "",
         null,
         3576031598965625,
         "2083-04-27",
         "2025-07-08T15:54:42.000Z",
         "part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T14:57:39.759Z"
        ],
        [
         5,
         "Carlos",
         "Burns",
         "cburns4@miitbeian.gov.cn",
         "",
         "169.113.235.40",
         "5602256255204850",
         "South Africa",
         "",
         null,
         "",
         "",
         null,
         5602256255204850,
         "2147-07-12",
         "2025-07-08T15:54:42.000Z",
         "part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         "2025-07-09T14:57:39.759Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "first_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "last_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "email",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ip_address",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "birthdate",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comments",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "_rescued_data",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cc_num",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cc_date",
            "nullable": true,
            "type": "date"
           },
           {
            "metadata": {},
            "name": "file_modification_time",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "source_file",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ingestion_time",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 13
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "birthdate",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comments",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cc_num",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cc_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "file_modification_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "source_file",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingestion_time",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop table if exists parquet_bronze;\n",
    "\n",
    "create table parquet_bronze as\n",
    "select *,\n",
    "  try_cast(cc as bigint) as cc_num,\n",
    "  cast(from_unixtime(cc_num/1000000)as date) as cc_date,\n",
    "  _metadata.file_modification_time as file_modification_time,\n",
    "  _metadata.file_name as source_file,\n",
    "  current_timestamp() as ingestion_time\n",
    "from read_files(\"/Volumes/workspace/v01/parquet\",format=>'parquet');\n",
    "\n",
    "select *\n",
    "  from parquet_bronze\n",
    "  limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20c402b1-494d-44f6-927e-a8adebbee001",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"source_file\":430},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752073190686}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>source_file</th><th>total</th></tr></thead><tbody><tr><td>part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>1000</td></tr><tr><td>part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>1000</td></tr><tr><td>part-00002-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet</td><td>1000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "part-00000-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         1000
        ],
        [
         "part-00001-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         1000
        ],
        [
         "part-00002-a9e77425-5fb4-456f-ba52-f821123bd193-c000.snappy.parquet",
         1000
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "source_file",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "total",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 16
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "source_file",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- exploring the metadata info from the table\n",
    "select source_file,count(*) as total\n",
    "  from parquet_bronze\n",
    "  group by source_file\n",
    "  order by source_file;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataEngineering with Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}